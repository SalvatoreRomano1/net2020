{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pygraphviz as pgv\n",
    "import pydot\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guerra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>portato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>casa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40014</th>\n",
       "      <td>#rip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40015</th>\n",
       "      <td>#aspettandoprometeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40016</th>\n",
       "      <td>#ivreich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40017</th>\n",
       "      <td>satanasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40018</th>\n",
       "      <td>consigliatissima</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40019 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "0                     diro\n",
       "1                    gente\n",
       "2                   guerra\n",
       "3                  portato\n",
       "4                     casa\n",
       "...                    ...\n",
       "40014                 #rip\n",
       "40015  #aspettandoprometeo\n",
       "40016             #ivreich\n",
       "40017            satanasso\n",
       "40018     consigliatissima\n",
       "\n",
       "[40019 rows x 1 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.read_csv('../../Scaricati/lemmas_unique_final.csv', index_col = 0)\n",
    "words = words.dropna().reset_index(drop = True)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Sentiment dictionary\n",
    "\n",
    "See here for better comprehension of the sentiment dictionary\n",
    "\n",
    "http://valeriobasile.github.io/twita/sentix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Wordnet synset ID</th>\n",
       "      <th>positive score</th>\n",
       "      <th>negative score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abile</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intelligente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capace</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incapace</td>\n",
       "      <td>a</td>\n",
       "      <td>2098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74604</th>\n",
       "      <td>imbronciarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74605</th>\n",
       "      <td>rannuvolarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74606</th>\n",
       "      <td>rasserenarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771169</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74607</th>\n",
       "      <td>rischiararsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771169</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74608</th>\n",
       "      <td>schiarirsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771169</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74606 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lemma POS  Wordnet synset ID  positive score  negative score  \\\n",
       "0             abile   a               1740           0.125            0.00   \n",
       "1      intelligente   a               1740           0.125            0.00   \n",
       "2           valente   a               1740           0.125            0.00   \n",
       "3            capace   a               1740           0.125            0.00   \n",
       "4          incapace   a               2098           0.000            0.75   \n",
       "...             ...  ..                ...             ...             ...   \n",
       "74604  imbronciarsi   v            2771020           0.000            0.25   \n",
       "74605  rannuvolarsi   v            2771020           0.000            0.25   \n",
       "74606  rasserenarsi   v            2771169           0.125            0.00   \n",
       "74607  rischiararsi   v            2771169           0.125            0.00   \n",
       "74608    schiarirsi   v            2771169           0.125            0.00   \n",
       "\n",
       "       polarity  intensity  \n",
       "0           1.0      0.125  \n",
       "1           1.0      0.125  \n",
       "2           1.0      0.125  \n",
       "3           1.0      0.125  \n",
       "4          -1.0      0.750  \n",
       "...         ...        ...  \n",
       "74604      -1.0      0.250  \n",
       "74605      -1.0      0.250  \n",
       "74606       1.0      0.125  \n",
       "74607       1.0      0.125  \n",
       "74608       1.0      0.125  \n",
       "\n",
       "[74606 rows x 7 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix = pd.read_csv('sentix/sentix', sep = \"\\t\", header = None, dtype = {'lemmas': object})\n",
    "sentix.columns = ['lemma', 'POS', 'Wordnet synset ID' ,'positive score', 'negative score', 'polarity','intensity']\n",
    "sentix = sentix.dropna()\n",
    "sentix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(my_value):\n",
    "    if my_value > 0.: \n",
    "        return +1.\n",
    "    elif my_value < 0.:\n",
    "        return -1.\n",
    "    elif my_value == 0.:\n",
    "        return 0.\n",
    "\n",
    "def get_exact_match(word, sentix):\n",
    "    subset = sentix[sentix.loc[:,'lemma'].str.fullmatch(word) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean - neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "def get_match(word, sentix):\n",
    "    subset = sentix[sentix.loc[:,'lemma'].str.match(word) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean - neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "def get_contains(word, sentix):\n",
    "    subset = sentix[sentix.loc[:,'lemma'].str.contains(word) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean - neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "def get_similar(word, sentix):\n",
    "    similar_words = difflib.get_close_matches(word, sentix.lemma, n = 8, cutoff = 0.8)\n",
    "    subset = sentix[sentix.loc[:,'lemma'].isin(similar_words) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean - neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "\n",
    "\n",
    "def get_rows_data(word, sentix, use_similarity = False):\n",
    "    \n",
    "    row = get_exact_match(word, sentix)\n",
    "    \n",
    "    #if there are no exact matches, try others\n",
    "    if (len(row) == 0):\n",
    "#         print('no exact match')\n",
    "        row = get_match(word, sentix)\n",
    "        \n",
    "        #if there are no matches, try the others\n",
    "        if (len(row) == 0):\n",
    "#             print('no match')\n",
    "            row = get_contains(word, sentix)\n",
    "            \n",
    "            #if word is not even contained and we want similarities then try it\n",
    "            if ((len(row) == 0) and (use_similarity)):\n",
    "#                 print('no contains')\n",
    "                row = get_similar(word, sentix)\n",
    "            \n",
    "                #if still no matches, give up and return an empty dataframe\n",
    "                if (len(row) == 0):\n",
    "#                     print('no similar')\n",
    "                    dictionary = {'lemma': [word], 'positive score' : [0.],'negative score' : [0.],\n",
    "                                  'polarity' : [0.],'intensity' : [0.]}\n",
    "                    row =  pd.DataFrame.from_dict(dictionary)\n",
    "            \n",
    "            #if we do not want similarities then return the empty dataframe        \n",
    "            elif (len(row) == 0):\n",
    "#                 print('no contains')\n",
    "                dictionary = {'lemma': [word], 'positive score' : [0.],'negative score' : [0.],\n",
    "                                  'polarity' : [0.],'intensity' : [0.]}\n",
    "                row = pd.DataFrame.from_dict(dictionary)\n",
    "        \n",
    "    #get back the original word    \n",
    "    row.lemma = word\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next call to the function get_rows_data(word, sentix, use_similarity = False) above does the following:\n",
    "\n",
    "+ **Output**: Returns a row of the kind (lemma, positive score, negative score, polarity, intensity)\n",
    "\n",
    "### **What it does**: it looks for a matching word in the sentix dataframe. \n",
    "* If there is one *exactly* matching, returns that row\n",
    "* if there are many, then compute the mean between the two positive and negative scores among the different rows, polarity is the sign of the difference (positive_score - negative_score) and intensity is the $L_2$ norm (i.e. sqrt(pos^2 + neg^2))\n",
    "* If there is **NONE** exactly matching, then look for any string that *matches* a word in the sentix dictionary. Same reasoning as before. If there is only one matching then returns that row, otherwise do some algebra.\n",
    "\n",
    "* If still there are none matching, then look for any string that *contains* (indeed to *contain* is a less strict relation that *matching* that in turn is a less strict relation than *exactly match*)\n",
    "\n",
    "* If still there are none contained, if a flag is set to true, then take the most similar words in the lemmas list and use them to create sentiment. \n",
    "\n",
    "* If even this way there are none, or the previous flag was set to false, return a row of the kind      (word, 0.  ,  0.  , 0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "first argument must be string or compiled pattern",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-57a13151b281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# for word in words.iloc[0:100,0]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msentiment_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_rows_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-230-ba036322868c>\u001b[0m in \u001b[0;36mget_rows_data\u001b[0;34m(word, sentix, use_similarity)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_rows_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_exact_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m#if there are no exact matches, try others\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-230-ba036322868c>\u001b[0m in \u001b[0;36mget_exact_match\u001b[0;34m(word, sentix)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_exact_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lemma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m                 )\n\u001b[1;32m   2000\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mfullmatch\u001b[0;34m(self, pat, case, flags, na)\u001b[0m\n\u001b[1;32m   2836\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mforbid_nonstring_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bytes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2837\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2838\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_fullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2839\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_fullmatch\u001b[0;34m(arr, pat, case, flags, na)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m     \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: first argument must be string or compiled pattern"
     ]
    }
   ],
   "source": [
    "sentiment_df = pd.DataFrame()\n",
    "# for word in words.iloc[0:100,0]:\n",
    "for word in words.iloc[:,0]:\n",
    "    sentiment_df = sentiment_df.append(get_rows_data(word, sentix, True), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.to_csv('lemmas_sentiment.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = pd.read_csv('lemmas_sentiment.csv')\n",
    "prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
