{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pygraphviz as pgv\n",
    "import pydot\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guerra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>portato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>casa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rimpatriare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>marcello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>perfavore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>patrio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>patriota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>difeso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>proprio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>radice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>soccombere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>islamico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>accoltellare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>uomo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>crocifisso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>collare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0           diro\n",
       "1          gente\n",
       "2         guerra\n",
       "3        portato\n",
       "4           casa\n",
       "5    rimpatriare\n",
       "6       marcello\n",
       "7      perfavore\n",
       "8         patrio\n",
       "9       patriota\n",
       "10        difeso\n",
       "11       proprio\n",
       "12        radice\n",
       "13    soccombere\n",
       "14          roma\n",
       "15      islamico\n",
       "16  accoltellare\n",
       "17          uomo\n",
       "18    crocifisso\n",
       "19       collare"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.read_csv('../../Scaricati/lemmas_unique_final.csv', index_col = 0)\n",
    "words.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Sentiment dictionary\n",
    "\n",
    "See here for better comprehension of the sentiment dictionary\n",
    "\n",
    "http://valeriobasile.github.io/twita/sentix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Wordnet synset ID</th>\n",
       "      <th>positive score</th>\n",
       "      <th>negative score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abile</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intelligente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capace</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incapace</td>\n",
       "      <td>a</td>\n",
       "      <td>2098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74604</th>\n",
       "      <td>imbronciarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74605</th>\n",
       "      <td>rannuvolarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74606</th>\n",
       "      <td>rasserenarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771169</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74607</th>\n",
       "      <td>rischiararsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771169</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74608</th>\n",
       "      <td>schiarirsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771169</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74606 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lemma POS  Wordnet synset ID  positive score  negative score  \\\n",
       "0             abile   a               1740           0.125            0.00   \n",
       "1      intelligente   a               1740           0.125            0.00   \n",
       "2           valente   a               1740           0.125            0.00   \n",
       "3            capace   a               1740           0.125            0.00   \n",
       "4          incapace   a               2098           0.000            0.75   \n",
       "...             ...  ..                ...             ...             ...   \n",
       "74604  imbronciarsi   v            2771020           0.000            0.25   \n",
       "74605  rannuvolarsi   v            2771020           0.000            0.25   \n",
       "74606  rasserenarsi   v            2771169           0.125            0.00   \n",
       "74607  rischiararsi   v            2771169           0.125            0.00   \n",
       "74608    schiarirsi   v            2771169           0.125            0.00   \n",
       "\n",
       "       polarity  intensity  \n",
       "0           1.0      0.125  \n",
       "1           1.0      0.125  \n",
       "2           1.0      0.125  \n",
       "3           1.0      0.125  \n",
       "4          -1.0      0.750  \n",
       "...         ...        ...  \n",
       "74604      -1.0      0.250  \n",
       "74605      -1.0      0.250  \n",
       "74606       1.0      0.125  \n",
       "74607       1.0      0.125  \n",
       "74608       1.0      0.125  \n",
       "\n",
       "[74606 rows x 7 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix = pd.read_csv('sentix/sentix', sep = \"\\t\", header = None, dtype = {'lemmas': object})\n",
    "sentix.columns = ['lemma', 'POS', 'Wordnet synset ID' ,'positive score', 'negative score', 'polarity','intensity']\n",
    "sentix = sentix.dropna()\n",
    "sentix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(my_value):\n",
    "    if my_value > 0.: \n",
    "        return +1.\n",
    "    elif my_value < 0.:\n",
    "        return -1.\n",
    "    elif my_value == 0.:\n",
    "        return 0.\n",
    "\n",
    "def get_exact_match(word, sentix):\n",
    "    subset = sentix[sentix.loc[:,'lemma'].str.fullmatch(word) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean - neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "def get_match(word, sentix):\n",
    "    subset = sentix[sentix.loc[:,'lemma'].str.match(word) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean - neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "def get_contains(word, sentix):\n",
    "    subset = sentix[sentix.loc[:,'lemma'].str.contains(word) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean - neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "def get_similar(word, sentix):\n",
    "    similar_words = difflib.get_close_matches(word, sentix.lemma, n = 8, cutoff = 0.8)\n",
    "    subset = sentix[sentix.loc[:,'lemma'].isin(similar_words) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean - neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "\n",
    "\n",
    "def get_rows_data(word, sentix, use_similarity = False):\n",
    "    \n",
    "    row = get_exact_match(word, sentix)\n",
    "    \n",
    "    #if there are no exact matches, try others\n",
    "    if (len(row) == 0):\n",
    "#         print('no exact match')\n",
    "        row = get_match(word, sentix)\n",
    "        \n",
    "        #if there are no matches, try the others\n",
    "        if (len(row) == 0):\n",
    "#             print('no match')\n",
    "            row = get_contains(word, sentix)\n",
    "            \n",
    "            #if word is not even contained and we want similarities then try it\n",
    "            if ((len(row) == 0) and (use_similarity)):\n",
    "#                 print('no contains')\n",
    "                row = get_similar(word, sentix)\n",
    "            \n",
    "                #if still no matches, give up and return an empty dataframe\n",
    "                if (len(row) == 0):\n",
    "#                     print('no similar')\n",
    "                    dictionary = {'lemma': [word], 'positive score' : [0.],'negative score' : [0.],\n",
    "                                  'polarity' : [0.],'intensity' : [0.]}\n",
    "                    row =  pd.DataFrame.from_dict(dictionary)\n",
    "            \n",
    "            #if we do not want similarities then return the empty dataframe        \n",
    "            elif (len(row) == 0):\n",
    "#                 print('no contains')\n",
    "                dictionary = {'lemma': [word], 'positive score' : [0.],'negative score' : [0.],\n",
    "                                  'polarity' : [0.],'intensity' : [0.]}\n",
    "                row = pd.DataFrame.from_dict(dictionary)\n",
    "        \n",
    "    #get back the original word    \n",
    "    row.lemma = word\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next call to the function get_rows_data(word, sentix, use_similarity = False) above does the following:\n",
    "\n",
    "+ **Output**: Returns a row of the kind (lemma, positive score, negative score, polarity, intensity)\n",
    "\n",
    "### **What it does**: it looks for a matching word in the sentix dataframe. \n",
    "* If there is one *exactly* matching, returns that row\n",
    "* if there are many, then compute the mean between the two positive and negative scores among the different rows, polarity is the sign of the difference (positive_score - negative_score) and intensity is the $L_2$ norm (i.e. sqrt(pos^2 + neg^2))\n",
    "* If there is **NONE** exactly matching, then look for any string that *matches* a word in the sentix dictionary. Same reasoning as before. If there is only one matching then returns that row, otherwise do some algebra.\n",
    "\n",
    "* If still there are none matching, then look for any string that *contains* (indeed to *contain* is a less strict relation that *matching* that in turn is a less strict relation than *exactly match*)\n",
    "\n",
    "* If still there are none contained, if a flag is set to true, then take the most similar words in the lemmas list and use them to create sentiment. \n",
    "\n",
    "* If even this way there are none, or the previous flag was set to false, return a row of the kind      (word, 0.  ,  0.  , 0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.DataFrame()\n",
    "# for word in words.iloc[0:100,0]:\n",
    "for word in words.iloc[:,0]:\n",
    "    sentiment_df = sentiment_df.append(get_rows_data(word, sentix, True), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.to_csv('lemmas_sentiment.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = pd.read_csv('lemmas_sentiment.csv')\n",
    "prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
