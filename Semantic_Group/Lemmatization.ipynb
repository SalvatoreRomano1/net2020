{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start this notebook from the final_text_cleaned file \n",
    "# generated from the Text_Preprocessing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.read_csv('/home/diego/Desktop/Networks/text_cleaned_final.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dire gente guerra portata casa rimpatriati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marcello perfavore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patria patrioti difesa proprie radici soccombe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>musulmani comandare casa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>odio dipende odio comandato libro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78170</th>\n",
       "      <td>vediamo ruspe inviate salvini ripulire ambient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78171</th>\n",
       "      <td>fine sente sempre richiamo africa parla diritt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78172</th>\n",
       "      <td>sparare ladri occhio penna barbetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78173</th>\n",
       "      <td>consigliatissima africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78174</th>\n",
       "      <td>taser donne chiamare pagliacci tali vedrai eff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75775 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "0             dire gente guerra portata casa rimpatriati\n",
       "1                                     marcello perfavore\n",
       "2      patria patrioti difesa proprie radici soccombe...\n",
       "3                               musulmani comandare casa\n",
       "4                      odio dipende odio comandato libro\n",
       "...                                                  ...\n",
       "78170  vediamo ruspe inviate salvini ripulire ambient...\n",
       "78171  fine sente sempre richiamo africa parla diritt...\n",
       "78172                sparare ladri occhio penna barbetta\n",
       "78173                            consigliatissima africa\n",
       "78174  taser donne chiamare pagliacci tali vedrai eff...\n",
       "\n",
       "[75775 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word4=[]\n",
    "\n",
    "for comment in final['text_clean']:\n",
    "    a=[word for word in comment.split()]\n",
    "    if len(a)>1:\n",
    "        for word in a:\n",
    "            word4.append(word)\n",
    "    else:\n",
    "        b=''.join(a)\n",
    "        word4.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584550"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_series=pd.Series(word4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=words_series.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58385"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.Series(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique words csv\n",
    "a.to_csv('/home/diego/Desktop/Networks/unique_words_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Lemmization in Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import it_core_news_lg\n",
    "nlp = it_core_news_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import _get_regex_pattern\n",
    "\n",
    "# get default pattern for tokens that don't get split\n",
    "re_token_match = _get_regex_pattern(nlp.Defaults.token_match)\n",
    "# add your patterns (here: hashtags and in-word hyphens)\n",
    "re_token_match = f\"({re_token_match}|#\\w+|\\w+-\\w+)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nlp = final[\"text_clean\"].apply(lambda text: nlp(text))\n",
    "final['text_nlp'] = text_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=pd.Series(final['text_nlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save all the tokens\n",
    "tokens.to_csv('all_tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token               \tLemma               \tPOS                 \tis-stop \tis-punct\n",
      "dire                \tdiro                \tAUX                 \t   0    \n",
      "gente               \tgente               \tNOUN                \t   0    \n",
      "guerra              \tguerra              \tNOUN                \t   0    \n",
      "portata             \tportato             \tVERB                \t   0    \n",
      "casa                \tcasa                \tNOUN                \t   0    \n",
      "rimpatriati         \trimpatriare         \tVERB                \t   0    \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Token':<20}\\t{'Lemma':<20}\\t{'POS':<20}\\t{'is-stop':<8}\\t{'is-punct':<8}\")\n",
    "for token in final['text_nlp'].loc[0]:\n",
    "    print(f\"{token.text:<20}\\t{token.lemma_:<20}\\t{token.pos_:<20}\\t{token.is_punct:^8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas=[]\n",
    "for i in final.index:\n",
    "    for token in final['text_nlp'][i]:\n",
    "        lemmas.append(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lemmas=pd.Series(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all lemmas\n",
    "all_lemmas.to_csv('lemmas_final_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40020"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_lemmas.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_unique=pd.Series(all_lemmas.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all unique lemmas\n",
    "lemmas_unique.to_csv('lemmas_unique_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
